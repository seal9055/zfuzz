* Gilbert Hoermann
* 03/01/2023 - 03/02/2023

My winter internship at Trail of Bits was mainly focused on writing a coverage-guided graybox fuzzer based on Qemu/Unicorn. After completing my initial work on the fuzzer I moved on to start looking at some targets to test it against. 

I decided to divide this writeup into 4 parts. In the following introduction, I want to talk a bit more about my goals with the fuzzer, and then move on to describe some Qemu & Unicorn internals since that is what I spent most of my first week on. In the second part, I dive deeper into the internals of the fuzzer and some of the design choices I made to support my goals with it. In the third part, I showcase how the fuzzer can be harnessed and used against different targets. Due to time limitations, this portion is not nearly as involved as I would have liked, but I still believe that it showcases some of the fuzzers strengths. In the final part, I leave a brief conclusion in which I try to objectively evaluate the fuzzer in its current state and describe some potential future work I would like to look into concerning this project.

The code for this fuzzer can be found here: https://github.com/trailofbits/2022-vr-winternship/tree/main/zfuzz

Goals with the Fuzzer

The motivation for this project was mainly based on a previous fuzzer I wrote, Sfuzz. For Sfuzz, I wrote a snapshot fuzzer based on a custom RISCV binary lifter, IR and JIT. Everything being handrolled allowed me to fully control target instrumentation and codegen to be optimized for fuzzing. With this, I was able to design a fuzzer that massively outperformed almost all fuzzers I tested it against while providing coverage collection, byte-level permissions, CmpCov, and more. Everything being architected from scratch also came with some very major drawbacks, however. I only supported RISCV and expanding it to be usable against impactful targets would require massive development efforts on the lifting/IR/JIT side. This means that all the results I was able to achieve ended in a proof-of-concept fuzzer that worked amazingly against simple targets but failed against anything more complex.

When I recently came across Unicorn I had the idea of trying to implement many of Sfuzz’s ideas on top of Unicorn's CPU-emulation framework. This would allow me to cut out a lot of Qemu’s complexity and focus on the aspects that made Sfuzz stand out over other fuzzers without having to worry about manually lifting and JIT compiling. 

To summarize, my main goal for this fuzzer is to have a coverage-guided snapshot fuzzer operating at high performance that can load arbitrary memory dumps and start fuzzing them from any given memory state. This fuzzer will never be useful in fuzzing complex userspace programs from their main function or Linux/Windows Kernel images. I do believe that the results showcase the fuzzer’s potential especially when targeting phones/embedded devices where memory dumps can be obtained and having access to source code is unrealistic.

Qemu

Qemu internals were the first topic I started looking into at the start of the internship, so I will be starting my writeup on this as well. Even though I never interacted with it directly for the fuzzer, getting a good understanding of Qemu helped me immensely in properly making use of Unicorn which is basically an emulator based almost entirely on ripping out parts of Qemu’s codebase.

Qemu is an emulator that supports various types of target/host configurations. It supports multiple popular architectures and provides full-system emulation, user-mode emulation, and various virtualization technologies. Full-system emulation is used to emulate entire operating systems. Qemu-user in comparison can be used to emulate individual binaries that may have been taken off of some operating system. To achieve these goals, Qemu provides different device/hardware models that the emulation targets can use to eg. emulate syscalls that aren’t available on the OS Qemu & the target are running on. Qemu also exposes the KVM virtualization model that allows the Linux kernel to act as a hypervisor. KVM is an official part of the mainline Linux kernel. Its strongest feature is that it allows emulation targets to run directly on the host without requiring explicit emulation/translations assuming that the host and target have the same architecture. This allows guests to achieve almost native performance instead of incurring the emulation overhead. This is accomplished by intercepting every impure operation a guest performs (eg. accessing hardware registers or interrupts) and passing off handling of this to Qemu. 

Let’s move on to talk about Qemu's memory model. A lot goes into this, especially when taking various hardware physical memory models into account that Qemu can support. Here I will mainly focus on the aspects that are directly relevant to the fuzzer. Guest physical ram is represented using an acyclic graph of MemoryRegions that contains ram & mmio regions in addition to more specialized regions to represent eg. memory buses. Additionally, AddressSpace objects are used to describe a mapping of guest addresses to MemoryRegion objects. This results in memory operations in the emulated code using AddressSpace to get a translation of an address to a MemoryRegion which then contains the memory that the guest is trying to operate on. There are a lot of details we could go into here such as the actual data being backed by RamBlock objects, or that Qemu can overlap MemoryRegions and assign priority numbers to determine which one should be used when an address is accessed that is in 2 regions, but I will conclude this section here. If you are curious, a lot more details on the general Memory Architecture, reference to relevant code sections, and some APIs that are exposed to interact with it are listed in the notes I took on this.

Finally let’s briefly cover TCG, Qemu’s general-purpose code generator. Qemu has multiple different “accelerators” that it can use to run the guest code on some host. A lot of these are platform/architecture-specific such as KVM for Linux, or WHP for Windows, and a lot of these are generally preferable to TCG due to their improved performance capabilities. TCG is much more general purpose and pretty much always works, and is the only accelerator Unicorn supports so I will be focusing on this. Qemu uses TCG as part of its JIT compiler. It takes an intermediate representation (IR) for some chunk of code as input and transforms that into assembly for your host architecture. The JIT engine pretty much just starts loading the guest’s code, one execution block at a time, and checks a translation cache if it has already compiled this block of code. If it has, it just jumps to the code it compiled for this previously. If it has not, it lifts the code block into its IR and passes it on to TCG which then generates and pushes the assembly instructions into the JIT cache. At the IR compilation stage, TCG supports some simple block-level optimizations but nothing that even comes close to the level of optimization LLVM performs. Most instructions are generically transformed from IR to host instructions. Some more specialized instructions that can’t be directly translated are emulated using Qemu's helper-function-model. For these instructions, an entire helper function is compiled and TCG inserts a call instruction to that helper function in the generated code. Memory accesses for example are handled by calls to such helpers. I provide several examples of how both the IR and final X86-host code look in the notes alongside some full code-traces that I generated using some simple gdb scripting that Peter Goodman helped me set up.

Qemu by default includes some interesting functionality to snapshot state based on dirtied memory that might have been interesting, but Unicorn did not adopt this feature so I did not look into this further.

Unicorn

Unicorn is a CPU emulator based on top of Qemu. This means it supports basically the exact same memory & compilation model as Qemu. Its main difference, which is also what pulled me towards it, is that it pulled out all of Qemu's complex hardware emulation code and exposes the pure emulator as a loadable library. This lets us invoke it like this to just run any code we give it.

```
let unicorn = Unicorn::init();
let code = load_code_from_disk();


unicorn.mem_write(load_addr, code);
unicorn.emulate(load_addr);
```

It also provides some simple hooking APIs that we can use to eg. intercept syscalls or memory operations which makes it really nice to set up & instrument targets for fuzzing. The API it exposes to users is mostly located here (I made some small modifications to the engine for my fuzzer so I forked the repo. I will explain these later). For a more in-depth layout of Unicorn, refer to my notes.
